{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1097b7e-b205-49f8-865c-a512d0a3a0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "── \u001b[1mConflicts\u001b[22m ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Loading required package: proxy\n",
      "\n",
      "\n",
      "Attaching package: 'proxy'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    as.dist, dist\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    as.matrix\n",
      "\n",
      "\n",
      "Loaded TSdist v3.7.1. See ?TSdist for help, citation(\"TSdist\") for use in publication.\n",
      "\n",
      "\n",
      "Registered S3 methods overwritten by 'TSA':\n",
      "  method       from    \n",
      "  fitted.Arima forecast\n",
      "  plot.Arima   forecast\n",
      "\n",
      "\n",
      "Attaching package: 'TSA'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:readr':\n",
      "\n",
      "    spec\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    acf, arima\n",
      "\n",
      "\n",
      "The following object is masked from 'package:utils':\n",
      "\n",
      "    tar\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'signal'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, poly\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'imputeTS'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:tseries':\n",
      "\n",
      "    na.remove\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'gridExtra'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'summarytools'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:tibble':\n",
      "\n",
      "    view\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr) # for data manipulation and transformation\n",
    "library(tidyverse) # for a collection of packages for data manipulation and visualization\n",
    "library(stats) # for statistical functions and models\n",
    "library(tsfeatures)\n",
    "library(lubridate)\n",
    "library(runner)\n",
    "\n",
    "library(TSdist) # for calculating distance measures between time series\n",
    "library(forecast) # for time series forecasting\n",
    "library(TSA) # for time series analysis\n",
    "library(tseries)\n",
    "library(signal)\n",
    "library(imputeTS)\n",
    "\n",
    "library(ggplot2) # for creating beautiful and customizable visualizations\n",
    "library(gridExtra) # for arranging multiple plots on a grid\n",
    "library(RColorBrewer) # for creating color palettes for your plots\n",
    "library(MLmetrics)\n",
    "library(summarytools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7425499b-d2c5-4b83-8999-13ff6c29597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path definitions\n",
    "\n",
    "ROOT <- \"../../\"\n",
    "\n",
    "DATA_PATH <- paste0(ROOT,\"data/\")\n",
    "\n",
    "DATA_INFO <- paste0(DATA_PATH,\"info/\")\n",
    "DATA_INFO_NIBIO_FILE <- paste0(DATA_INFO ,\"lmt.nibio.csv\")\n",
    "DATA_INFO_FROST_FILE <- paste0(DATA_INFO,\"Frost_stations.csv\")\n",
    "DATA_FILE_SOIL_STATIONS <- paste0(DATA_INFO,\"'Stasjonsliste jordtemperatur modellering.xlsx'\")\n",
    "\n",
    "DATA_COLLECTION <- paste0(DATA_PATH,\"raw_data/\")\n",
    "DATA_COLLECTION_STAT <- paste0(DATA_COLLECTION,\"Veret paa Aas 2013- 2017/\") # pattern -> 'Veret paa Aas 2013- 2017/Veret paa Aas {YYYY}.pdf'\n",
    "DATA_COLLECTION_TIME <- paste0(DATA_COLLECTION,\"Time 2013- 2023/\") # pattern -> Time{YYYY}.xlsx\n",
    "DATA_COLLECTION_NIBIO <- paste0(DATA_COLLECTION,\"nibio/\") # pattern -> weather_data_hour_stID{id}_y{year}.csv\n",
    "\n",
    "# ID definitions\n",
    "\n",
    "station_names <- read.csv(DATA_INFO_NIBIO_FILE,\n",
    "                          header=TRUE,\n",
    "                          row.names=\"ID\",\n",
    "                          colClasses=c(ID=\"integer\",Navn=\"character\"))\n",
    "\n",
    "nibio_id = list(\n",
    "    Innlandet = c(11,17,18,26,27),\n",
    "    Trøndelag = c(15,57,34,39,43),\n",
    "    Østfold = c(37,41,52,118,5),\n",
    "    SørVestlandet = c(14,29,32,48,22),\n",
    "    Vestfold = c(30,38,42,50)\n",
    ")\n",
    "\n",
    "# function definitions\n",
    "\n",
    "file_name.nibio <- function(station_id, year, path = NULL){\n",
    "    if(is.null(path)){\n",
    "        pattern = paste0(DATA_COLLECTION_NIBIO,\"weather_data_hour_stID\",station_id,\"_y\",year,\".csv\")\n",
    "    } else {\n",
    "        pattern = sprintf(path,station_id,year)\n",
    "    }\n",
    "    return(pattern)\n",
    "}\n",
    "\n",
    "data.nibio <- function(station_id,year, path = NULL){\n",
    "    path <- file_name.nibio(station_id,year, path = path)\n",
    "    data_nibio <- read.csv(path,\n",
    "                       header=T, col.names = c(\"Time\",\"TM\",\"RR\",\"TJM10\",\"TJM20\"))\n",
    "    data_nibio <- mutate(data_nibio,across(\n",
    "                                    \"Time\",\n",
    "                                  str2date))\n",
    "    data_nibio <- column_to_rownames(data_nibio, var = \"Time\")\n",
    "    data_nibio <- mutate_at(data_nibio,c(\"TM\",\"RR\",\"TJM10\",\"TJM20\"), as.numeric)\n",
    "    return(data_nibio)\n",
    "}\n",
    "na.interpol.cust <- function(data, maxgap = Inf, n.p, \n",
    "                             s.window = 10, alg.option = \"linear\"){\n",
    "    data.decomp <- stlplus::stlplus(data,n.p = n.p, s.window = s.window)\n",
    "    data.new <- rep(0,length.out = length(data))\n",
    "    for(part in c(\"seasonal\", \"trend\", \"remainder\")){\n",
    "        data.new <- data.new + na_interpolation(data.decomp$data[,part],\n",
    "                                                maxgap=maxgap,\n",
    "                                                option = alg.option)\n",
    "    }\n",
    "    return(data.new)\n",
    "}\n",
    "str2date <- function(x) {\n",
    "    return(as.POSIXlt(paste0(x,\"00\"),\n",
    "                      format = \"%Y-%m-%d %H:%M:%S%z\",\n",
    "                      tz=\"GMT\"))\n",
    "}\n",
    "\n",
    "na.interplol.kal <-function(data, maxgap = Inf, n.p, \n",
    "                             s.window = 10, alg.option = \"StructTS\"){\n",
    "    data.decomp <- stlplus::stlplus(data,n.p = n.p, s.window = s.window)\n",
    "    data.new <- rep(0,length.out = length(data))\n",
    "    for(part in c(\"seasonal\", \"trend\", \"remainder\")){\n",
    "        data.new <- data.new + na_kalman(data.decomp$data[,part],\n",
    "                                                maxgap=maxgap,\n",
    "                                                model = alg.option,\n",
    "                                        smooth = TRUE)\n",
    "    }\n",
    "    return(data.new)\n",
    "}\n",
    "\n",
    "find.na.index.length <- function(x){ # antar at x er bool vektor\n",
    "    i <- 1 # starting index\n",
    "    na.data <- data.frame()\n",
    "    while(i <= length(x)){\n",
    "        sample.data <- x[i:length(x)]\n",
    "        first <- match(T, sample.data, nomatch = -1)\n",
    "        if(first < 0) {\n",
    "            break\n",
    "        }\n",
    "        last <- match(F, sample.data[first:length(sample.data)], nomatch = length(sample.data[first:length(sample.data)])+1) - 2 + first\n",
    "\n",
    "        na.data <- rbind(na.data, data.frame(Length = c(last-first + 1), First = c(first+i-1), Last = c(last+i-1)))\n",
    "        i <- i + last\n",
    "    }\n",
    "    return(na.data)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921de49-e8d4-499a-b980-0f844dff0413",
   "metadata": {},
   "source": [
    "## Data behandling\n",
    "\n",
    "Henter data fra csv filer som er hentet fra NiBio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618f8a3-7569-4113-8d2b-24b6f4d9c87f",
   "metadata": {},
   "source": [
    "## Imputerings metode\n",
    "\n",
    "Undersøker om dekomponering er bedre enn naiv imputering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c83c0-17c3-4475-b7b2-f6f4cddbf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks.index <- c()\n",
    "len.na <- 8\n",
    "len.val <- 12\n",
    "\n",
    "data.check <- 1:5880\n",
    "i <- 0\n",
    "while(i < 5880){\n",
    "    i <- i + len.val - 1\n",
    "    blocks.index <- append(blocks.index,seq(i,i+len.na-1))\n",
    "    i <- i + len.na\n",
    "}\n",
    "blocks.index <- blocks.index[blocks.index <= 5880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea1f26-a63a-4c2d-850d-d3aa77c75d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(moments)\n",
    "data_nibio_no_na <- data.nibio(14,2019)\n",
    "col.name <- \"TM\"\n",
    "\n",
    "faulty.data <- data_nibio_no_na\n",
    "faulty.data[blocks.index,col.name] <- NA\n",
    "\n",
    "fixed.data <- na_interpolation(faulty.data[,col.name], option=\"spline\", method = \"periodic\")\n",
    "abs.diff <- fixed.data - data_nibio_no_na[,col.name]\n",
    "print(paste(\"µ\",mean(abs.diff),\"std:\",sqrt(var(abs.diff)),\"skewness:\",skewness(abs.diff)))\n",
    "plot((abs.diff),xlim = c(0,5880))\n",
    "\n",
    "fixed.data <- na.interpol.cust(faulty.data[,col.name], n.p = 21,alg.option=\"spline\", method = \"periodic\")\n",
    "abs.diff <- fixed.data - data_nibio_no_na[,col.name]\n",
    "print(paste(\"µ\",mean(abs.diff),\"std:\",sqrt(var(abs.diff)),\"skewness:\",skewness(abs.diff)))\n",
    "plot((abs.diff),xlim = c(0,5880))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac2843-4bd6-4814-be7b-b27a24dfed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RR hadde ikke noe serlig, men hadde en rep ~= 31 (måned baser?)\n",
    "# TM ~= 24? \n",
    "# TJM10 ~= 24?\n",
    "# TJM20 ~= 21?\n",
    "perid <- c(TM = 24,TJM10 = 24, TJM20 = 24, RR = 31)\n",
    "\n",
    "data.rle <- rle(is.na(data_nibio[,\"TJM20\"]))\n",
    "data.max <- max(data.rle$lengths[data.rle$values])\n",
    "indexes <- find.index.rle.bool(data.rle,data.max)\n",
    "print(data.max)\n",
    "\n",
    "for(col in c(\"TJM20\")){\n",
    "    imput <- as.ts(na.interpol.cust(data_nibio[,col],n.p=perid[col]))\n",
    "    plot(imput,xlim = c(indexes[1]-100,indexes[2]+100))\n",
    "    abline(v=indexes[1],col = \"red\")\n",
    "    abline(v=indexes[2],col = \"red\")\n",
    "    title(paste(col,\"STL + naive\"))\n",
    "}\n",
    "\n",
    "for(col in c(\"TJM20\")){\n",
    "    imput <- as.ts(na_interpolation(data_nibio[,col]))\n",
    "    plot(imput,xlim = c(indexes[1]-100,indexes[2]+100))\n",
    "    abline(v=indexes[1],col = \"red\")\n",
    "    abline(v=indexes[2],col = \"red\")\n",
    "    title(paste(col,\"naive\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c7027-a9ac-4d93-b102-964f36739a10",
   "metadata": {},
   "source": [
    "## Data Analyse\n",
    "\n",
    "Analyserer data for manglede verdier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b73653-e88d-4aea-9c5b-a5480aee1f44",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "feature.name = c(\"TM\",\"RR\",\"TJM10\",\"TJM20\")\n",
    "na.run.tables <- c()\n",
    "full.count <- c()\n",
    "\n",
    "notible_run <- 24*7\n",
    "warning_run <- 8*2 # imputering fra begge ender\n",
    "\n",
    "cat(\"Null count of data.\",\n",
    "            file = \"data.txt\",sep=\"\\n\")\n",
    "cat(paste(\"notable runs,defined by nb length\",notible_run,\"and warning length\",warning_run,\"\\n###############################\"),\n",
    "            file = \"NB_data.txt\",sep=\"\\n\")\n",
    "\n",
    "station_names <- read.csv(DATA_INFO_NIBIO_FILE,\n",
    "                          header=TRUE,\n",
    "                          row.names=\"ID\",\n",
    "                          colClasses=c(ID=\"integer\",Navn=\"character\"))\n",
    "\n",
    "na.run.station.year.feature <- list()\n",
    "\n",
    "sub_set <- unlist(nibio_id)\n",
    "\n",
    "all.id <- as.numeric(rownames(station_names))\n",
    "\n",
    "for(id in all.id){\n",
    "    # beginning plot\n",
    "    svg(file = paste0(ROOT,\"plots/plot-\",id,\"-\",station_names[as.character(id),],\".svg\"))\n",
    "    plot(NULL,\n",
    "         sub = \"hourly time From 2014-03-01 to year 2020-10-31\",\n",
    "         xlab=\"Date\", ylab=\"NA location\",\n",
    "         xlim = c(0,5881), ylim = c(2013,2021))   \n",
    "\n",
    "    colours <- c(TM =\"blue\", RR = \"red\",TJM10 = \"green\",TJM20 = \"orange\")\n",
    "    lev <- seq(-1/2,1/2,length.out=5)\n",
    "    names(lev) <- feature.name\n",
    "    \n",
    "    numb <- 0\n",
    "    denom <- 0\n",
    "    na.run.count <- matrix(rep(0,length=5880*4),nrow = 5880, ncol = 4)\n",
    "    colnames(na.run.count) <- feature.name\n",
    "    na.count <- c()\n",
    "    na.count.year <- c()\n",
    "    na.matrix.total <- NULL\n",
    "    #na.run.station.year.feature[[as.character(id)]] <- c()\n",
    "    #data_plot <- ggplot(title = paste(\"NA count of staion:\",station_names[as.character(id),],\"id:\",id))\n",
    "    na.plot <- FALSE\n",
    "    cat(paste(\"***************\",\"station\",id,\"***************\"),append=T,sep=\"\\n\",file = \"NB_data.txt\")\n",
    "    for(year in seq(2014,2020)){\n",
    "\n",
    "        # Drawing seperating lines\n",
    "\n",
    "        lines(c(0,5880),c(year + 1/2,year + 1/2), col = \"black\")\n",
    "        \n",
    "        #lev <- seq(-1/2,1/2,length.out=5)\n",
    "        #names(lev) <- c(\"TM\",\"RR\",\"TJM10\",\"TJM20\")\n",
    "        #lev\n",
    "        #lev[\"TJM20\"]\n",
    "        #lev[match(\"TJM20\",names(lev))+1]\n",
    "        cat(paste(\":::::::year\",year,\":::::::\"),append=T,sep=\"\\n\",file = \"NB_data.txt\")\n",
    "        data_nibio <- suppressWarnings(data.nibio(id,year)) # henter data\n",
    "        data_nibio <- data_nibio[rownames(data_nibio) ,]#> paste0(year,\"-04-01\"),]\n",
    "        data_nibio_raw <- suppressWarnings(data.nibio(id,\n",
    "                                     year,\n",
    "                                     path=paste0(DATA_COLLECTION_NIBIO,\n",
    "                                                 \"weather_data_raw_hour_stID%i_y%i.csv\"\n",
    "                                                )\n",
    "                                    ))\n",
    "        \n",
    "        data_nibio_raw[!is.na(data_nibio_raw[,\"TM\"]) & (data_nibio_raw[,\"TM\"] <= 0),\"RR\"] <- NA \n",
    "\n",
    "        data_nibio[1:nrow(data_nibio_raw),\"RR\"] <- data_nibio_raw[1:nrow(data_nibio_raw),\"RR\"]\n",
    "\n",
    "        #na.run.station.year.feature[[as.character(id)]][[as.character(year)]] <- c()\n",
    "        \n",
    "        # Na analesys\n",
    "\n",
    "        cat(\"--------Matrix representation, and pair NA's---------\",append =T,sep=\"\\n\\t\",file = \"NB_data.txt\")\n",
    "\n",
    "        data.matrix <- as.matrix(ifelse(is.na(data_nibio),1,0))\n",
    "\n",
    "        data.matrix.sq <- t(data.matrix)%*%data.matrix\n",
    "        if(is.null(na.matrix.total)){\n",
    "            na.matrix.total <- data.matrix.sq \n",
    "        } else {\n",
    "            na.matrix.total <- na.matrix.total + data.matrix.sq\n",
    "        }\n",
    "        \n",
    "        cat(\"\\t\",append=T,file = \"NB_data.txt\",sep = \"\\t\")\n",
    "        suppressWarnings(write.table(data.matrix.sq,append =T,file = \"NB_data.txt\",sep = \"\\t\"))\n",
    "\n",
    "        cat(paste(\"Total NA:\",sum(diag(data.matrix.sq))),file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "        \n",
    "        na.check <- is.na(data_nibio)\n",
    "        if(any(na.check)){\n",
    "            if(length(na.count) == 0){\n",
    "                na.count <- ifelse(na.check, 1, 0)\n",
    "            } else {\n",
    "                na.count <- na.count + ifelse(na.check, 1, 0)\n",
    "            }\n",
    "            #na.count.year[[as.character(year)]] <- sum(na.check)/(nrow(data_nibio)*4)\n",
    "            na.plot <- TRUE\n",
    "            \n",
    "            for(cols in feature.name){ # checker run for hver kolonne\n",
    "                run_table <- table(NULL)\n",
    "                cat(paste(\"\\n--------------station\",id,\"year\",year,\"feature\",cols,\"--------------\"),\n",
    "                          file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "                if(sum(na.check[,cols]) > 0){\n",
    "                    run_na <- find.na.index.length(na.check[,cols])\n",
    "                    #na.run.station.year.feature[[as.character(id)]][[as.character(year)]][[as.character(cols)]] <- table(run_na)\n",
    "                    #print(paste(\"year:\",year,\"feature:\",cols))\n",
    "                    #print(run_na)\n",
    "\n",
    "                    points(c(0,0,0,0),lev[1:4] + year + 1/8, col = colours)\n",
    "\n",
    "                    for(ind in 1:nrow(run_na)){    \n",
    "                        c <- run_na[ind,\"Length\"]\n",
    "                        dates <- rownames(data_nibio)[c(run_na$First[ind],run_na$Last[ind])]\n",
    "                        if(any(is.na(dates))){\n",
    "                            print(dates)\n",
    "                        }\n",
    "                        cat(paste(\"\\t-\\t\",dates[1],\"|->\",c,\"run\",ifelse(c != 1,paste(\"\\t|->\",dates[2]),\"\"),\"\\t\"),\n",
    "                                file = \"NB_data.txt\",append=T,sep=\"\") \n",
    "                        # plot conditions\n",
    "\n",
    "                        if(c == 1){\n",
    "                            # plot dot\n",
    "                            points(run_na$First[ind],year + lev[cols] + 1/8, col = colours[cols])\n",
    "                        } else {\n",
    "                            # plot rectangle\n",
    "                            rect(run_na$First[ind],year + lev[cols],\n",
    "                                 run_na$Last[ind],year + lev[match(cols,names(lev))+1],\n",
    "                                 col = colours[cols], border = NA\n",
    "                                )\n",
    "                        }\n",
    "\n",
    "                        # Write condition\n",
    "                        \n",
    "                         if(c >= notible_run){\n",
    "                            cat(\"(NB!)\",file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "                        } else if(c > warning_run) {\n",
    "                            cat(\"(Warning)\",\n",
    "                                file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "                        } else {\n",
    "                            cat(\"\",\n",
    "                                file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "                        }\n",
    "                        na.run.count[c,cols] <- na.run.count[c,cols] + 1\n",
    "                    }\n",
    "                    run_table <- t(as.matrix(table(run_na$Length)))\n",
    "                }\n",
    "                \n",
    "                cat(paste(\"\\n--------------Total for station\",id,\"year\",year,\"in feature\",cols,\"--------------\"),\n",
    "                          file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "                cat(\"\\t\",append=T,file = \"NB_data.txt\",sep = \"\\t\")\n",
    "                suppressWarnings(write.table(run_table,file = \"NB_data.txt\",append=T,sep = \"\\t\"))\n",
    "                cat(paste(\"\\t- total :\\t\",sum(na.check[,cols])),\n",
    "                    file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "            }\n",
    "        } else {\n",
    "            cat(paste(\"\\t- year\",year,\"without NA.\"),\n",
    "                                file = \"NB_data.txt\",append=T,sep=\"\\n\")\n",
    "            if(length(full.count[[as.character(id)]]) == 0){\n",
    "                full.count[[as.character(id)]] <- 1/7\n",
    "            } else {\n",
    "                full.count[[as.character(id)]] <- full.count[[as.character(id)]] + 1/7\n",
    "            }\n",
    "        }\n",
    "        cat(paste(\":::::::END year\",year,\"END:::::::\"),append=T,sep=\"\\n\",file = \"NB_data.txt\")\n",
    "    }\n",
    "\n",
    "    legend(x = \"topright\",legend=feature.name, fill = colours)\n",
    "\n",
    "    if(na.plot){\n",
    "        cat(paste(\"============ END station\",id,\"END =============\"),append=T,sep=\"\\n\",file = \"NB_data.txt\")\n",
    "        cat(paste(\"Staion nr \",id),\n",
    "            file = \"data.txt\",append=T,sep=\"\\n\")\n",
    "        #suppressWarnings(write.table(bad_data,file = \"data.txt\",append=T)) # add labels... somehow\n",
    "        cat(paste(\"prosent of\",id,\":\",sum(na.count)/(nrow(data_nibio)*4)),\n",
    "            file = \"data.txt\",append=T,sep=\"\\n\")\n",
    "        cat(paste(\"prosent of\",id,\" for years:\"),\n",
    "            file = \"data.txt\",append=T,sep=\"\\n\")\n",
    "        cat(paste0(unlist(na.count.year), collapse = \"\\n\"),\n",
    "            file = \"data.txt\",append=T,sep=\"\\n\")      \n",
    "        cat(\"\\t\",append=T,file = \"NB_data.txt\",sep = \"\\t\")\n",
    "        suppressWarnings(write.table(na.matrix.total,file = \"NB_data.txt\",append=T,sep = \"\\t\"))\n",
    "        cat(paste(\"Total:\",sum(diag(na.matrix.total))),file = \"NB_data.txt\", append =T, sep = \"\\n\")\n",
    "    }\n",
    "    title(main = paste0(\"NA count of station: \", station_names[as.character(id),],\n",
    "                         \" id: \",id,\n",
    "                \" Total:\",sum(diag(na.matrix.total))),\n",
    "         sub = paste0(\"From date 2014-03-01 to date 2020-10-31\")\n",
    "    dev.off()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05d9c0-eee6-4ffd-b09f-ed43d5c572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data.nibio(16,2017)[,\"TM\"],type=\"l\")\n",
    "plot(forecast(fit,h=24*7),xlim=c(5500,6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172b13e-1ae6-4474-b5a7-59e5dbfa0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "imput_data <- na_interpolation(as.ts(data_nibio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff05bc2-dc75-4533-b03a-76b58529de47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RR hadde ikke noe serlig, men hadde en rep ~= 31 (måned baser?)\n",
    "# TM ~= 24? \n",
    "# TJM10 ~= 24?\n",
    "# TJM20 ~= 21?\n",
    "for(col in c(\"TM\",\"TJM10\",\"TJM20\")){\n",
    "    acf(imput_data[,col])\n",
    "    title(col)\n",
    "    pacf(imput_data[,col])\n",
    "    title(col)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa750fb-676d-4b59-8df1-089c3dd79e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(stlplus::stlplus(imput_data[,\"RR\"],n.p = 31, s.window = 5,s.degree=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e91a4-37b0-4ebc-b1a7-c7be9596a857",
   "metadata": {},
   "source": [
    "DEtte virker som nice statestik, men hvordan utvide dette til flere år når det er forskjellige vekstperioder? Kan jo prøve å dekomponere dem, så summere residualene under antagelsen at perioden for få stasjoner representerer ikke bare alle år, men alle stasjoner! Som er veldig grovt i min mening, men hva annet kan jeg gjøre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a165d-e85e-45cf-b513-924f2da5583e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stat_id = matrix()\n",
    "\n",
    "for(id in nibio_id){\n",
    "    csv_files <- list.files(path = DATA_COLLECTION_NIBIO,\n",
    "                        pattern = regex(paste0(\".*ID\",id,\"_y\\\\d{4}.csv\")),\n",
    "                                        full.names = TRUE)\n",
    "    combined_data <- lapply(csv_files,\n",
    "                        read.csv,\n",
    "                        header=T, \n",
    "                        col.names = c(\"Time\",\"TM\",\"RR\",\"TJM10\",\"TJM20\")) %>% bind_rows()\n",
    "    combined_data <- combined_data %>% column_to_rownames(., var = 'Time')\n",
    "    combined_data <- mutate_at(combined_data,c(\"TM\",\"RR\",\"TJM10\",\"TJM20\"), as.numeric)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a2083-a506-4b3a-8eb3-300b79206631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library( datasets )\n",
    "data(\"faithful\")\n",
    "# z - scores & M a h a l a n o b i s d i s t a n c e\n",
    "z <- scale(imput_data) %>% as.data.frame()\n",
    "mahalanobis(z , center = c(0 ,0) , cov = cov( imput_data,use = \"all.obs\" ) )\n",
    "# DBSCAN & LOF\n",
    "library( dbscan )\n",
    "dbscan( imput_data , eps = 1)$cluster == 0\n",
    "lof( imput_data , minPts = 5)\n",
    "# I s o l a t i o n forest\n",
    "library( isotree )\n",
    "iso_mod <- isolation.forest( imput_data )\n",
    "predict( iso_mod , newdata = imput_data )\n",
    "# one - class SVM\n",
    "library( e1071 )\n",
    "svm_mod <- svm ( imput_data , type = \"one-classification\")\n",
    "print(sum(predict( svm_mod , newdata = imput_data )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eae073-1d05-40e2-9f68-4f410e615781",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.test(imputed.data[,\"TJM10\"])\n",
    "kpss.test(imputed.data[,\"TJM10\"])\n",
    "pp.test(imputed.data[,\"TJM10\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
