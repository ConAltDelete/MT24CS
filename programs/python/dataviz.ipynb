{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002fa039-b352-4270-ad6e-b64938c6ad64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data visualisation\n",
    "\n",
    "We start by importing the data and do analisys on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a3daaf-5523-4eb4-8746-282cc18d81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import datetime\n",
    "\n",
    "# path definitions\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "DATA_INFO = \"info/\"\n",
    "DATA_INFO_NIBIO_FILE = DATA_INFO + \"lmt.nibio.csv\"\n",
    "DATA_INFO_FROST_FILE = DATA_INFO + \"Frost_stations.csv\"\n",
    "DATA_FILE_SOIL_STATIONS = DATA_INFO + \"'Stasjonsliste jordtemperatur modellering.xlsx'\"\n",
    "\n",
    "DATA_COLLECTION = DATA_PATH + \"raw_data/\"\n",
    "DATA_COLLECTION_STAT = DATA_COLLECTION + \"Veret paa Aas 2013- 2017/\" # pattern -> 'Veret paa Aas 2013- 2017/Veret paa Aas {YYYY}.pdf'\n",
    "DATA_COLLECTION_TIME = DATA_COLLECTION + \"Time 2013- 2023/\" # pattern -> Time{YYYY}.xlsx\n",
    "DATA_COLLECTION_NIBIO = DATA_COLLECTION + \"nibio/\" # pattern -> weather_data_stID{id}.csv\n",
    "\n",
    "# ID definitions\n",
    "\n",
    "nibio_id = [\n",
    "    29,32,48,22,\n",
    "\t17,18,10,14,\n",
    "\t43,39,34,57,\n",
    "\t5,108,30,41\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613cd50-8242-45f1-abd3-4eccfcb6b054",
   "metadata": {},
   "source": [
    "The data is splitted among two collections of data, one is a pdf and the other is a `.xlsx` format. We start by collecting the data from the hourly data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86033f4a-3c0a-40ed-acdb-9c122b15ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_frost():\n",
    "    \"\"\"\n",
    "        Frost API deliver a json format.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def time_nibio():\n",
    "    global nibio_id #! need to change later.\n",
    "    \n",
    "    daily_2014_2020 = {\n",
    "        i : pd.DataFrame() for i in nibio_id\n",
    "    }\n",
    "    for id in nibio_id:\n",
    "        daily_2014_2020[id] = pd.read_csv(DATA_COLLECTION_NIBIO + \"weather_data_stID{}.csv\".format(id),\n",
    "                                          delimiter = \",\",\n",
    "                                          header = 0)\n",
    "        # daily_2014_2020[id][[\"Time measured\"]] = pd.to_datetime(daily_2014_2020[id][[\"Time measured\"]], format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "        # daily_2014_2020[id][[\"Time measured\"]] = daily_2014_2020[id][[\"Time measured\"]].apply(datetime.datetime.strptime,args=(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "\n",
    "    return daily_2014_2020\n",
    "        \n",
    "\n",
    "def time_nmbu():\n",
    "    hourly_data_2013_2023 = {\n",
    "        i : pd.DataFrame() for i in range(2013,2024)\n",
    "    }\n",
    "    for i in range(2016,2024): # starts from 2016 rather than 2013 due to difference in data quality\n",
    "        raw_data = pd.read_excel(DATA_COLLECTION_TIME + \"Time{}.xlsx\".format(i)) # fetching data\n",
    "        raw_data[\"DATO\"] = pd.to_datetime(raw_data[\"DATO\"], format=\"%d%m%y %H\")\n",
    "        raw_data = raw_data.set_index(\"DATO\") # setting the date as index\n",
    "        if len(set([\"JT10\",\"JT20\",\"LT\",\"NB\"]).intersection(raw_data.columns)) == 4:\n",
    "            hourly_data_2013_2023[i] = raw_data[[\"JT10\",\"JT20\",\"LT\",\"NB\"]] # selects only a few columns.\n",
    "        else:\n",
    "            print(\"WARNING: Table:\" + str(i) + \" has missing columns.\\nMissing:\" + str([ a for a in [\"JT10\",\"JT20\",\"LT\",\"NB\"] if a not in raw_data.columns]))\n",
    "    return hourly_data_2013_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb7535c-78c1-4360-ae30-0e9c352026ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = time_nibio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71a94e-ed3c-468c-86a4-7dadacc4be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_time_merge(*tables: pd.DataFrame) pd.DataFrame:\n",
    "    new_table = pd.dataframe()\n",
    "    mu = [0,0]\n",
    "    sigma = [0,0]\n",
    "    for t in range(len(tables[0])): # starts at 0 but in python -1 will become the last value in a list.\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d829d9a-6b51-4d5e-b95d-eb6397050a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
